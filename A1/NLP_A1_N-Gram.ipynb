{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_A1_N-Gram.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *N-Gram Language Model*"
      ],
      "metadata": {
        "id": "svQxhHEQszsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "Vr7-hKfetJcW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evh--eC-Et9b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import argparse\n",
        "from itertools import product\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess Data"
      ],
      "metadata": {
        "id": "aVyWKju1tc3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOS = \"<s> \"\n",
        "EOS = \"</s>\"\n",
        "UNK = \"<UNK>\""
      ],
      "metadata": {
        "id": "Dtz3XBW3HSdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sentence_tokens(sentences, n):\n",
        "    sos = SOS * (n-1) if n > 1 else SOS\n",
        "    return ['{}{} {}'.format(sos, s, EOS) for s in sentences]\n",
        "\n",
        "def replace_singletons(tokens):\n",
        "    vocab = nltk.FreqDist(tokens)\n",
        "    return [token if vocab[token] > 2 else UNK for token in tokens]\n",
        "    # return [token for token in tokens]\n",
        "\n",
        "def preprocess(text, n):\n",
        "    sentences = text.split('\\n')\n",
        "    sentences = add_sentence_tokens(sentences, n)\n",
        "    tokens = ' '.join(sentences).split(' ')\n",
        "    tokens = replace_singletons(tokens)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "vt82XcORHdGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Language Model Class"
      ],
      "metadata": {
        "id": "Fm6WsjmqtsjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Language_Model:\n",
        "\n",
        "    def __init__(self, train_text, n, laplace = 1):\n",
        "        self.n = n\n",
        "        self.laplace = laplace\n",
        "        self.tokens = preprocess(train_text, n)\n",
        "        self.vocab  = nltk.FreqDist(self.tokens)\n",
        "        if(UNK not in self.vocab):\n",
        "            self.vocab[UNK] = 0\n",
        "        self.model  = self._create_model()\n",
        "        self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
        "\n",
        "    def _smooth(self):\n",
        "        vocab_size = len(self.vocab)\n",
        "\n",
        "        n_grams = nltk.ngrams(self.tokens, self.n)\n",
        "        self.n_vocab = nltk.FreqDist(n_grams)\n",
        "\n",
        "        m_grams = nltk.ngrams(self.tokens, self.n-1)\n",
        "        self.m_vocab = nltk.FreqDist(m_grams)\n",
        "\n",
        "        def smoothed_count(n_gram, n_count):\n",
        "            m_gram = n_gram[:-1]\n",
        "            m_count = self.m_vocab[m_gram]\n",
        "            return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
        "\n",
        "        return { n_gram: smoothed_count(n_gram, count) for n_gram, count in self.n_vocab.items() }\n",
        "\n",
        "    def _create_model(self):\n",
        "        if self.n == 1:\n",
        "            num_tokens = len(self.tokens)\n",
        "            return { (unigram, ): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "        else:\n",
        "            return self._smooth()\n",
        "\n",
        "    def _calculate_prob(self, ngram):\n",
        "        if(ngram in  self.model):\n",
        "            return self.model[ngram]\n",
        "        else:\n",
        "            numerator, denominator = 1, len(self.vocab)\n",
        "            if(ngram in self.n_vocab):\n",
        "                numerator += self.n_vocab[ngram]\n",
        "            m_gram = ngram[:-1]\n",
        "            if(m_gram in self.m_vocab):\n",
        "                denominator += self.m_vocab[m_gram]\n",
        "            return numerator / denominator\n",
        "\n",
        "    def perplexity(self, test_data):\n",
        "        test_tokens = preprocess(test_data, self.n)\n",
        "        test_tokens = [token if token in self.vocab else UNK for token in test_tokens]\n",
        "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
        "\n",
        "        N = len(test_tokens)\n",
        "        probabilities = [self._calculate_prob(ngram) for ngram in test_ngrams]\n",
        "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
        "\n",
        "    def _best_candidate(self, prev, i=0, without=[]):\n",
        "        blacklist  = [\"<UNK>\"] + without\n",
        "        candidates = ((ngram[-1],prob) for ngram,prob in self.model.items() if ngram[:-1]==prev)\n",
        "        candidates = filter(lambda candidate: candidate[0] not in blacklist, candidates)\n",
        "        candidates = sorted(candidates, key=lambda candidate: candidate[1], reverse=True)\n",
        "        if len(candidates) == 0:\n",
        "            return (\"</s>\", 1)\n",
        "        else:\n",
        "            return candidates[0 if prev != () and prev[-1] != \"<s>\" else i]\n",
        "     \n",
        "    def generate_random_sentences(self, num, min_len=12, max_len=24):\n",
        "        for i in range(num):\n",
        "            sent, prob = [\"<s>\"] * max(1, self.n-1), 1\n",
        "            # print(sent)\n",
        "            while sent[-1] != \"</s>\":\n",
        "                prev = () if self.n == 1 else tuple(sent[-(self.n-1):])\n",
        "                blacklist = sent + ([\"</s>\"] if len(sent) < min_len else [])\n",
        "                next_token, next_prob = self._best_candidate(prev, i, without=blacklist)\n",
        "                sent.append(next_token)\n",
        "                prob *= next_prob\n",
        "                \n",
        "                if len(sent) >= max_len:\n",
        "                    sent.append(\"</s>\")\n",
        "\n",
        "            yield ' '.join(sent), -1/math.log(prob)\n",
        "\n",
        "    def generate_sentences(self, text = \" \", min_len=12, max_len=24):\n",
        "        sent, prob = [\"<s>\"] * max(1, self.n-1) + text.lower().split(\" \"), 1\n",
        "        while sent[-1] != \"</s>\":\n",
        "            prev = () if self.n == 1 else tuple(sent[-(self.n-1):])\n",
        "            blacklist = sent + ([\"</s>\"] if len(sent) < min_len else [])\n",
        "            next_token, next_prob = self._best_candidate(prev, without=blacklist)\n",
        "            sent.append(next_token)\n",
        "            prob *= next_prob\n",
        "                  \n",
        "            if len(sent) >= max_len:\n",
        "                sent.append(\"</s>\")\n",
        "\n",
        "        return ' '.join(sent), -1/math.log(prob)"
      ],
      "metadata": {
        "id": "XRJdk8YwE3Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "MA_idADlt4Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('train.txt', 'r+')\n",
        "train_text = f.read()\n",
        "f.close()\n",
        "\n",
        "f = open('test.txt', 'r+')\n",
        "test_text = f.read()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "YNBDGDA3FGkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unigram Model"
      ],
      "metadata": {
        "id": "bEEdAxazt-iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1\n",
        "model = Language_Model(train_text,n)\n",
        "print(\"Unigram Model Perplexity : \",model.perplexity(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHMZ7fzLt22G",
        "outputId": "582c3b86-fa68-41f6-e53a-00816819c7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Model Perplexity :  663.5046858332885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random Sentences Generated:\")\n",
        "for sentence, prob in model.generate_random_sentences(10):\n",
        "      print(\"{} ({:.5f})\".format(sentence, prob))\n",
        "\n",
        "input_text = \"The company Said that\"\n",
        "sentence, prob = model.generate_sentences(input_text)\n",
        "print(\"\\n\\nPredicted Sentence for input text \\\"{}\\\": \".format(input_text))\n",
        "print(\"{} ({:.5f})\".format(sentence, prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6NEMlH4vvq1",
        "outputId": "3961cb1c-6c57-4503-f437-d5d05e57cba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentences Generated:\n",
            "<s> the of to in and said a mln for dlrs vs </s> (0.02054)\n",
            "<s> of to in and said a mln for dlrs vs it </s> (0.01978)\n",
            "<s> to in and said a mln for dlrs vs it pct of on is from its that at by be cts year will </s> (0.00904)\n",
            "<s> in and said a mln for dlrs vs it pct on to is from its that at by be cts year will with </s> (0.00890)\n",
            "<s> and said a mln for dlrs vs it pct on is in from its that at by be cts year will with billion </s> (0.00876)\n",
            "<s> said a mln for dlrs vs it pct on is from and its that at by be cts year will with billion net </s> (0.00864)\n",
            "<s> a mln for dlrs vs it pct on is from its said that at by be cts year will with billion net was </s> (0.00853)\n",
            "<s> mln for dlrs vs it pct on is from its that a at by be cts year will with billion net was us </s> (0.00841)\n",
            "<s> for dlrs vs it pct on is from its that at mln by be cts year will with billion net was us he </s> (0.00830)\n",
            "<s> dlrs vs it pct on is from its that at by for be cts year will with billion net was us he has </s> (0.00821)\n",
            "\n",
            "\n",
            "Predicted Sentence for input text \"The company Said that\": \n",
            "<s> the company said that of to in and a mln for </s> (0.03136)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bi-Gram Model"
      ],
      "metadata": {
        "id": "lZmUx11HuCWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 2\n",
        "model = Language_Model(train_text,n)\n",
        "print(\"Bi-gram Model Perplexity : \",model.perplexity(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXqa_ZGUuDKr",
        "outputId": "374b4e06-cf3e-4ed9-99a8-73d35ca06d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bi-gram Model Perplexity :  676.1738793566435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random Sentences Generated:\")\n",
        "for sentence, prob in model.generate_random_sentences(10):\n",
        "      print(\"{} ({:.5f})\".format(sentence, prob))\n",
        "\n",
        "input_text = \"The company Said that\"\n",
        "sentence, prob = model.generate_sentences(input_text)\n",
        "print(\"\\n\\nPredicted Sentence for input text \\\"{}\\\": \".format(input_text))\n",
        "print(\"{} ({:.5f})\".format(sentence, prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MysB7Z-Zv2yv",
        "outputId": "39b590bd-9b59-4162-8b5e-28b4614ff499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentences Generated:\n",
            "<s> the company said it has been made a share in 1986 </s> (0.02266)\n",
            "<s> it said the company also be a share in 1986 87 03 09 pct of its board </s> (0.01294)\n",
            "<s> shr loss of the company said it has been made a share </s> (0.02084)\n",
            "<s> he said it has been made a share in the company </s> (0.02241)\n",
            "<s> in the company said it has been made a share of its board </s> (0.01802)\n",
            "<s> but the company said it has been made a share in 1986 </s> (0.01982)\n",
            "<s> a share in the company said it has been made by an agreement to be used for one of its board </s> (0.01078)\n",
            "<s> us and the company said it has been made a share </s> (0.02116)\n",
            "<s> this year shr loss of the company said it has been made a share </s> (0.01778)\n",
            "<s> they said it has been made a share in the company </s> (0.02133)\n",
            "\n",
            "\n",
            "Predicted Sentence for input text \"The company Said that\": \n",
            "<s> the company said that it has been made a share in 1986 </s> (0.02667)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tri-Gram Model"
      ],
      "metadata": {
        "id": "F0S6nKZ_uD_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "model = Language_Model(train_text,n)\n",
        "print(\"Tri-gram Model Perplexity : \", model.perplexity(test_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-pAc0TGuEki",
        "outputId": "bc758c74-1ee8-42ba-f8a1-7734fc321c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tri-gram Model Perplexity :  2731.673073427145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random Sentences Generated:\")\n",
        "for sentence, prob in model.generate_random_sentences(10):\n",
        "      print(\"{} ({:.5f})\".format(sentence, prob))\n",
        "\n",
        "input_text = \"The company Said that\"\n",
        "sentence, prob = model.generate_sentences(input_text)\n",
        "print(\"\\n\\nPredicted Sentence for input text \\\"{}\\\": \".format(input_text))\n",
        "print(\"{} ({:.5f})\".format(sentence, prob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOxM35xVv3bM",
        "outputId": "751db88c-af4f-47df-e6ac-b24670626024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentences Generated:\n",
            "<s> <s> the company said it has agreed to sell its shares in a statement </s> (0.01445)\n",
            "<s> <s> it said the company also announced an offering of up to one billion dlrs in cash and notes </s> (0.00886)\n",
            "<s> <s> shr loss one ct vs profit two cts net 119 mln dlrs </s> (0.01261)\n",
            "<s> <s> he said the company also announced an offering of up to one billion dlrs in cash and notes </s> (0.00882)\n",
            "<s> <s> in a statement that the us agriculture department said it has agreed to sell its shares </s> (0.01066)\n",
            "<s> <s> but the company said it has agreed to sell its shares in a statement </s> (0.01251)\n",
            "<s> <s> a spokesman for the first quarter of 1986 and 1985 </s> (0.01601)\n",
            "<s> <s> us officials said the company also announced an offering of up to one billion dlrs in cash and notes </s> (0.00797)\n",
            "<s> <s> this is a major trade bill that would be the first quarter of 1986 </s> (0.01051)\n",
            "<s> <s> they said the company also announced an offering of up to one billion dlrs in cash and notes </s> (0.00856)\n",
            "\n",
            "\n",
            "Predicted Sentence for input text \"The company Said that\": \n",
            "<s> <s> the company said that if they are not yet been reached </s> (0.01742)\n"
          ]
        }
      ]
    }
  ]
}